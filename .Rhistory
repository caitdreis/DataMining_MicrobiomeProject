library(ISLR)
library(MASS)
library(ggplot2)
library(gbm)
library(glmnet)
library(ROCR)
library(e1071)
library(tidyverse)
set.seed(225)
x1 <- rnorm(n=33, mean=40, sd=9)
x2 <- rnorm(n=34, mean=70, sd=12)
x3 <- rnorm(n=33, mean=100, sd=9)
y1 <- rnorm(n=33, mean=50, sd=20)
y2 <- rnorm(n=34, mean=20, sd=20)
y3 <- rnorm(n=33, mean=50, sd=20)
data <- data.frame(x=c(x1,x2,x3),y=c(y1,y2,y3),z=NA)
data$z[1:33] <- "a"
data$z[34:67] <- "b"
data$z[68:100] <- "a"
data$z <- as.factor(data$z)
train <- sample_n(data,70)
test <- setdiff(data,train)
qplot(x, y, colour = z, data = train)
svm1 <- svm(z~., kernel="linear",cost=2,scale=FALSE, data=train)
svm_pred <- predict(svm1, train)
qplot(x, y, colour = z, shape = svm_pred,
data = train)
svm_err <- table(pred = svm_pred, true = train$z)
svm_err
svmrad = svm(z~.,data=train, kernel="radial", gamma=10,
cost=3)
rad_pred <- predict(svmrad, train)
qplot(x, y, colour = z, shape = rad_pred,
data = train)
rad_err <- table(pred = rad_pred, true = train$z)
rad_err
svm_pred <- predict(svm1, test)
qplot(x, y, colour = z, shape = svm_pred, data = test)
svm_err <- table(pred = svm_pred, true = test$z)
svm_err
rad_pred <- predict(svmrad, test)
qplot(x, y, colour = z, shape = rad_pred, data = test)
rad_err <- table(pred = rad_pred, true = test$z)
rad_err
x1=runif(500)-0.5
x2=runif(500)-0.5
y=1*(x1^2-x2^2 > 0)
data2 <- data.frame(x1=x1,x2=x2,y=as.factor(y))
qplot(x1, x2, colour = y, data = data2)
glm <- glm(y~.,family="binomial"(link='logit'),data=data2)
glm_pred <- predict(glm, data2)
glm_pred
glm_pred[glm_pred>0.5] <- 1
glm_pred[glm_pred<0.5] <- 0
glm_pred <- as.factor(glm_pred)
qplot(x1, x2, colour = glm_pred, data = data2)
rad_err <- table(pred = glm_pred, true = data2$y)
rad_err
logx2 <- glm(y~log(abs(x2))+x1,family="binomial"(link='logit'),data=data2)
glm_pred <- predict(logx2, data2)
glm_pred[glm_pred>0.5] <- 1
glm_pred[glm_pred<0.5] <- 0
glm_pred <- as.factor(glm_pred)
qplot(x1, x2, colour = glm_pred, data = data2)
rad_err <- table(pred = glm_pred, true = data2$y)
rad_err
svm1 <- svm(y~., kernel="linear",cost=2,scale=FALSE, data=data2)
svm_pred <- predict(svm1, data2)
qplot(x1, x2, colour = svm_pred, data = data2)
rad <- svm(y~., kernel="radial",gamma=10,cost=10,data=data2)
rad_pred <- predict(rad, data2)
qplot(x1, x2, colour = rad_pred, data = data2)
set.seed(2)
x1 <- rnorm(n=100, mean=40, sd=9)
x2 <- rnorm(n=100, mean=50, sd=12)
y1 <- rnorm(n=100, mean=50, sd=20)
y2 <- rnorm(n=100, mean=20, sd=20)
data <- data.frame(x=c(x1,x2),y=c(y1,y2),z=NA)
data$z[1:100] <- "a"
data$z[101:200] <- "b"
data$z <- as.factor(data$z)
train <- sample_n(data,150)
test <- setdiff(data,train)
qplot(x, y, colour = z, data = train)
svm1 <- svm(z ~., data=train)
tune.out = tune(svm, z~x+y, data=train, kernel="linear",
ranges=list(cost = c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)))
summary(tune.out)
costs <- c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)
for (x in costs){
svm <- svm(z~., kernel="linear",cost=x,scale=FALSE, data=train)
svm_pred <- predict(svm, train)
tab <- table(svm_pred,train$z)
error <- 1-sum(diag(tab))/sum(tab)
print(x)
print(error)
}
costs <- c(0.01, 0.1, 1, 5, 10, 100, 1000)
for (x in costs){
svm <- svm(z~., kernel="linear",cost=x,scale=FALSE, data=train)
svm_pred <- predict(svm, test)
tab <- table(svm_pred,test$z)
error <- 1-sum(diag(tab))/sum(tab)
print(x)
print(error)
}
svm10000 <- svm(z~., kernel="linear",cost=10000,scale=FALSE, data=train)
svm_pred <- predict(svm10000, test)
tab <- table(svm_pred,test$z)
error <- 1-sum(diag(tab))/sum(tab)
print(x)
print(error)
svm1 <- svm(z ~., data=train)
tune.out = tune(svm, z~x+y, data=train, kernel="linear",
ranges=list(cost = c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)))
rm(svm)
tune.out = tune(svm, z~x+y, data=train, kernel="linear",
ranges=list(cost = c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)))
summary(tune.out)
costs <- c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)
for (x in costs){
svm1 <- svm(z~., kernel="linear",cost=x,scale=FALSE, data=train)
svm_pred <- predict(svm1, train)
tab <- table(svm_pred,train$z)
error <- 1-sum(diag(tab))/sum(tab)
print(x)
print(error)
}
costs <- c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)
for (x in costs){
svm <- svm(z~., kernel="linear",cost=x,scale=FALSE, data=train)
svm_pred <- predict(svm, test)
tab <- table(svm_pred,test$z)
error <- 1-sum(diag(tab))/sum(tab)
print(x)
print(error)
}
attach(Auto)
auto=Auto
View(auto)
auto["y"] = NA
median(mpg)
which[auto$mpg>median(mpg)]
which[auto$mpg>median(auto$mpg)]
median(mpg)
which[mpg>median(mpg)]
which(mpg>median(mpg))
auto[which(mpg>median(mpg))]
over<-which(mpg>median(mpg))
over<-which(mpg>=median(mpg))
under<-which(mpg<median(mpg))
auto[over,"y"]<-1
auto[under,"y"]<-0
tune.out = tune(svm, as.factor(y)~., data=auto, kernel="linear",
ranges=list(cost = c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)))
rm(svm)
tune.out = tune(svm, as.factor(y)~., data=auto, kernel="linear",
ranges=list(cost = c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)))
summary(tune.out)
tune.out=tune(svm,as.factor(y)~.,data=auto,kernel="radial",
ranges=list(cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4)))
summary(tune.out)
tune.out=tune(svm,as.factor(y)~.,data=auto,kernel="polynomial",
ranges=list(cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4)),
degree=c(2,3,4,5))
summary(tune.out)
tune.out=tune(svm,as.factor(y)~.,data=auto,kernel="polynomial",
ranges=list(cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4),degree=c(2,3,4,5)))
summary(tune.out)
plot(tune.out$best.model, auto) #where svmfit contains your fitted model and
plot(svm,tune.out$best.model, auto) #where svmfit contains your fitted model and
plot(tune.out$best.model, svm,auto) #where svmfit contains your fitted model and
plot(tune.out$best.model,auto) #where svmfit contains your fitted model and
qplot(displacement, acceleration, colour = y, data = auto)
auto$y <- as.factor(auto$y)
qplot(displacement, acceleration, colour = y, data = auto)
qplot(horsepower, weight, colour = y, data = auto)
qplot(horsepower, acceleration, colour = y, data = auto)
qplot(horsepower, weight, acceleration, colour = y, data = auto)
svm1 <- svm(z~., kernel="linear",cost=1,scale=FALSE, data=auto)
svm1 <- svm(y~., kernel="linear",cost=1,scale=FALSE, data=auto)
svm_pred <- predict(svm1, auto)
plot(svm1,auto)
plot(svm,auto)
plot(svm1,data=auto)
plot(svm(y~., kernel="linear",cost=1,scale=FALSE, data=auto),data=auto)
plot(svm(y~., kernel="linear",cost=1),data=auto)
plot(svm(y~., kernel="linear",cost=1,data=auto))
qplot(displacement, acceleration, colour = y, shape = svm_pred,
data = auto)
svmrad = svm(z~.,data=train, kernel="radial", gamma=0.5,
cost=10)
rad_pred <- predict(svmrad, train)
qplot(displacement, acceleration, colour = y, shape = rad_pred,
data = auto)
svmrad = svm(z~.,data=train, kernel="radial", gamma=0.5,
cost=10)
rad_pred <- predict(svmrad, train)
qplot(displacement, acceleration, colour = y, shape = rad_pred,
data = auto)
rad_pred
svmrad = svm(z~.,data=train, kernel="radial", gamma=0.5,
cost=10)
rad_pred <- predict(svmrad, train)
rad_pred
qplot(displacement, acceleration, colour = y, shape = rad_pred,
data = auto)
svmrad = svm(z~.,data=auto, kernel="radial", gamma=0.5,
cost=10)
rad_pred <- predict(svmrad, auto)
svmrad = svm(y~.,data=auto, kernel="radial", gamma=0.5,
cost=10)
rad_pred <- predict(svmrad, auto)
qplot(displacement, acceleration, colour = y, shape = rad_pred,
data = auto)
svm1 <- svm(y~., kernel="linear",cost=1,scale=FALSE, data=auto)
svm_pred <- predict(svm1, auto)
qplot(displacement, acceleration, colour = y, shape = svm_pred,
data = auto)
svmrad = svm(y~.,data=auto, kernel="polynomial", gamma=0.5,
cost=1,degree=3)
svmpoly = svm(y~.,data=auto, kernel="polynomial", gamma=0.5,
cost=1,degree=3)
poly_pred <- predict(svmpoly, auto)
qplot(displacement, acceleration, colour = y, shape = poly_pred,
data = auto)
library(tidyverse) # Load the core tidyverse packages: ggplot2, tibble,
library(qpcR)
library(MASS)
library(readxl)
library(plot3D)
library(car)
library(glmnet)
setwd("~/Desktop/DSI/STAT 6021/Homeworks/6")
B1 <- read_excel("data-table-B1.xls") #Read in the xls data file
B3.1 <- read_excel("data-table-B3-1.xls") #Read in the xls data file
B11 <- read_excel("data-table-B11.xls") #Read in the xls data file
B18 <- read_excel("data-table-B18.xls") #Read in the xls data file
B19 <- read_excel("data-table-B19.xls") #Read in the xls data file
cor(B3.1[,2:12])
B3.lm <- lm(y~., data=B3.1)
vif(B3.lm)
cor(B18[,2:9])
B18.lm <- lm(y~., data=B18)
vif(B18.lm)
cor(B19[,2:11])
B19.lm <- lm(y~., data=B19)
vif(B19.lm) #this produces an error: "there are aliased coefficients in the model"
alias(B19.lm)
B19.lm <- lm(y~.-x10-x7, data=B19)
vif(B19.lm)
colMeans(B3.1, na.rm=TRUE) #x3=217.900000
B3.1$x3[is.na(B3.1$x3)] <- 217.9
B3.1m <- as.matrix(B3.1)
ridge <- glmnet(B3.1m[,2:12], B3.1m[,1], alpha=0, lambda=0.01)
coef(s.ridge)
ridge2 <- glmnet(B3.1m[,2:12], B3.1m[,1], alpha=0)
library(tidyverse) # Load the core tidyverse packages: ggplot2, tibble,
library(qpcR)
library(MASS)
library(readxl)
library(plot3D)
library(car)
library(glmnet)
setwd("~/Desktop/DSI/STAT 6021/Homeworks/6")
B1 <- read_excel("data-table-B1.xls") #Read in the xls data file
B3.1 <- read_excel("data-table-B3-1.xls") #Read in the xls data file
B11 <- read_excel("data-table-B11.xls") #Read in the xls data file
B18 <- read_excel("data-table-B18.xls") #Read in the xls data file
B19 <- read_excel("data-table-B19.xls") #Read in the xls data file
cor(B3.1[,2:12])
B3.lm <- lm(y~., data=B3.1)
vif(B3.lm)
cor(B18[,2:9])
B18.lm <- lm(y~., data=B18)
vif(B18.lm)
cor(B19[,2:11])
B19.lm <- lm(y~., data=B19)
vif(B19.lm) #this produces an error: "there are aliased coefficients in the model"
alias(B19.lm)
B19.lm <- lm(y~.-x10-x7, data=B19)
vif(B19.lm)
colMeans(B3.1, na.rm=TRUE) #x3=217.900000
B3.1$x3[is.na(B3.1$x3)] <- 217.9
B3.1m <- as.matrix(B3.1)
ridge <- glmnet(B3.1m[,2:12], B3.1m[,1], alpha=0, lambda=0.01)
coef(ridge)
ridge2 <- glmnet(B3.1m[,2:12], B3.1m[,1], alpha=0)
plot(ridge2, xvar="lambda",label=TRUE)
setwd("~/Documents/GitHub/DataMining_MicrobiomeProject")
setwd("~/Documents/GitHub/DataMining_MicrobiomeProject")
data <- read.csv("MicrobiomeWithMetadata", encoding = 'utf-8', stringsAsFactors = FALSE)
data <- read.csv("MicrobiomeWithMetadata.csv", encoding = 'utf-8', stringsAsFactors = FALSE)
microbiome <- read.csv("MicrobiomeWithMetadata.csv", encoding = 'utf-8', stringsAsFactors = FALSE)
View(microbiome)
ridge <- glmnet(B3.1m[,2:12], B3.1m[,1], alpha=0, lambda=7)
coef(ridge)
ridge <- glmnet(B3.1m[,2:12], B3.1m[,1], alpha=0, lambda=.2)
coef(ridge)
ridge <- glmnet(B3.1m[,2:12], B3.1m[,1], alpha=0, lambda=7)
coef(ridge)
vif(ridge)
vif(B3.lm)
summary(ridge)
ridge$RSS
cv.glmnet(B3.1m[,2:12], B3.1m[,1], alpha = 0, lambda = lambdas)
cv.glmnet(B3.1m[,2:12], B3.1m[,1], alpha = 0)
cv.fit <- cv.glmnet(B3.1m[,2:12], B3.1m[,1], alpha = 0)
plot(cv.fit)
opt_lambda <- cv_fit$lambda.min
opt_lambda
opt.lambda <- cv.fit$lambda.min
opt.lambda
fit <- cv.fit$glmnet.fit
summary(fit)
y_predicted <- predict(fit, s = opt_lambda, newx = B3.1m[,2:12])
y_predicted <- predict(fit, s = opt.lambda, newx = B3.1m[,2:12])
sst <- sum(y^2)
B3.1m$y
fit$sse
fit$y
B3.1m[,1]
sst <- sum((B3.1m[,1])^2)
sse <- sum((y_predicted - (B3.1m[,1]))^2)
rsq <- 1 - sse / sst
rsq <- 1 - (sse / sst)
rsq
summary(B3.lm)
sst
sse
299/14325
y_predicted <- predict(fit, s = .2, newx = B3.1m[,2:12])
sst <- sum((B3.1m[,1])^2)
sse <- sum((y_predicted - (B3.1m[,1]))^2)
299/14325
rsq <- 1 - (sse / sst)
rsq = 0.9791508
y_predicted <- predict(fit, s = .2, newx = B3.1m[,2:12])
sst <- sum((B3.1m[,1])^2)
sse <- sum((y_predicted - (B3.1m[,1]))^2)
rsq <- 1 - (sse / sst)
rsq = 0.9791508
opt.lambda <- cv.fit$lambda.min
opt.lambda
y_predicted <- predict(fit, s = 6.14, newx = B3.1m[,2:12])
sst <- sum((B3.1m[,1])^2)
sse <- sum((y_predicted - (B3.1m[,1]))^2)
rsq <- 1 - (sse / sst)
rsq = 0.9791508
y_predicted <- predict(fit, s = .2, newx = B3.1m[,2:12])
sst <- sum((B3.1m[,1])^2)
sse <- sum((y_predicted - (B3.1m[,1]))^2)
rsq <- 1 - (sse / sst)
rsq #0.9791508
y_predicted <- predict(fit, s = opt.lambda, newx = B3.1m[,2:12])
sst <- sum((B3.1m[,1])^2)
sse <- sum((y_predicted - (B3.1m[,1]))^2)
rsq <- 1 - (sse / sst)
rsq #0.9791508
y_predicted <- predict(B3.lm, newx = B3.1m[,2:12])
sst <- sum((B3.1[,1])^2)
sse <- sum((y_predicted - (B3.1m[,1]))^2)
sse <- sum((y_predicted - (B3.1[,1]))^2)
rsq <- 1 - (sse / sst)
rsq #0.9791508
View(B1)
NFL.null <- lm(y~1, data=B1)
NFL.full <- lm(y~., data=B1)
step(NFL.null, scope=list(lower=NFL.null, upper=NFL.full), direction="forward")
step(NFL.full, scope=list(lower=NFL.null, upper=NFL.full), direction="backward")
step(NFL.null, scope=list(lower=NFL.null, upper=NFL.full), direction="both")
library(leaps)
bestmod <- regsubsets(Sales~., data=sdata, nbest=10)
bestmod <- regsubsets(y~., data=B1, nbest=10)
summary(bestmod)
s.rss = summary(bestmod)$rss
s.adjr2 = summary(bestmod)$adjr2
s.cp = summary(bestmod)$cp
s.bic = summary(bestmod)$bic
NFL.rss = summary(bestmod)$rss
NFL.adjr2 = summary(bestmod)$adjr2
NFL.cp = summary(bestmod)$cp
NFL.bic = summary(bestmod)$bic
NFL.df = data.frame(NFL.rss,NFL.adjr2,NFL.cp,NFL.bic)
order(NFL.df$NFL.adjr2)
order(NFL.df$NFL.rss)
order(NFL.df$NFL.bic)
order(NFL.df$NFL.cp)
View(NFL.df)
View(B11)
bestmod <- regsubsets(Quality~., data=B11, nbest=10)
wine.cp = summary(bestmod)$cp
wine.cp
order(wine.cp)
summary(bestmod)
bestmod <- regsubsets((Quality~Flavor*(I(Region==1)+I(Region==2)+I(Region==3)), data=B11))
bestmod <- regsubsets((Quality~Flavor*(I(Region==1)+I(Region==2)+I(Region==3))), data=B11)
wine.cp = summary(bestmod)$cp
order(wine.cp)
summary(bestmod)
bestmod$sserr
bestmod$rss
b
bestmod <- regsubsets(Quality~., data=B11, nbest=10)
wine.cp = summary(bestmod)$cp
order(wine.cp)
summary(bestmod)
bestmod$rss
summary(bestmod)$res
(bestmod)$res
plot((bestmod)$res)
plot((bestmod)$res,)
plot(winecp, xlab = "Number of Variables", ylab = "Cp")
plot(wine.cp, xlab = "Number of Variables", ylab = "Cp")
which.min(wine.cp)
points(10, wine.cp[10], pch = 20, col = "red")
points(17, wine.cp[17], pch = 20, col = "red")
plot(wine.cp, xlab = "Number of Variables", ylab = "Cp")
which.min(wine.cp)
points(17, wine.cp[17], pch = 20, col = "red")
bestmod <- regsubsets(Quality~., data=B11, nvmax = 6)
wine.cp = summary(bestmod)$cp
order(wine.cp)
summary(bestmod)
plot(wine.cp, xlab = "Number of Variables", ylab = "Cp")
points(3, wine.cp[3], pch = 20, col = "red")
View(B1)
bestmod <- regsubsets(y~., data=B1, nvmax = 9)
NFL.rss = summary(bestmod)$rss
NFL.adjr2 = summary(bestmod)$adjr2
NFL.cp = summary(bestmod)$cp
NFL.bic = summary(bestmod)$bic
NFL.df = data.frame(NFL.rss,NFL.adjr2,NFL.cp,NFL.bic)
order(NFL.df$NFL.adjr2)
order(NFL.df$NFL.rss)
order(NFL.df$NFL.bic)
order(NFL.df$NFL.cp)
summary(bestmod)
bestmod <- regsubsets(Quality~., data=B11, nvmax = 6)
wine.cp = summary(bestmod)$cp
order(wine.cp)
summary(bestmod)
plot(wine.cp, xlab = "Number of Variables", ylab = "Cp")
points(3, wine.cp[3], pch = 20, col = "red")
bestmod <- regsubsets(Quality~I(Region==1)+I(Region==2)+I(Region==3)+
Flavor+Clarity+Aroma+Body+Oakiness, data=B11, nvmax = 8)
wine.cp = summary(bestmod)$cp
order(wine.cp)
summary(bestmod)
wine.cp = summary(bestmod)$cp
order(wine.cp) #4 3 5 6 7 2 1
summary(bestmod)
plot(wine.cp, xlab = "Number of Variables", ylab = "Cp")
points(3, wine.cp[3], pch = 20, col = "red")
points(4, wine.cp[4], pch = 20, col = "red")
plot(wine.cp, xlab = "Number of Variables", ylab = "Cp")
points(4, wine.cp[4], pch = 20, col = "red")
CP1 <- lm(Quality~I(Region==1)+I(Region==2)+
Flavor+Oakiness, data=B11)
CP2 <- lm(Quality~I(Region==1)+I(Region==3)+
Flavor, data=B11)
CP1$PRESS
sumamry(CP1)$PRESS
summary(CP1)$PRESS
summary(CP1)
ei <- residuals(CP1)
qqnorm(ei)
qqline(ei)
ei <- residuals(CP2)
qqnorm(ei)
qqline(ei)
press(CP1)
PRESS <- function(linear.model) {
#' calculate the predictive residuals
pr <- residuals(linear.model)/(1-lm.influence(linear.model)$hat)
#' calculate the PRESS
PRESS <- sum(pr^2)
return(PRESS)
}
PRESS(CP1)
PRESS(CP2)
wine.null <- lm(y~1, data=B11)
wine.full <- lm(y~., data=B11)
wine.full <- lm(y~., data=B11,drop.unused.levels = FALSE)
wine.full <- lm(y~., data=B11,drop.unused.levels = TRUE)
wine.full <- lm(y~Quality~I(Region==1)+I(Region==2)+I(Region==3)+
Flavor+Clarity+Aroma+Body+Oakiness, data=B11,drop.unused.levels = TRUE)
View(B11)
wine.null <- lm(Quality~1, data=B11)
wine.full <- lm(Quality~I(Region==1)+I(Region==2)+I(Region==3)+
Flavor+Clarity+Aroma+Body+Oakiness, data=B11,drop.unused.levels = TRUE)
wine.full <- lm(Quality~I(Region==1)+I(Region==2)+I(Region==3)+
Flavor+Clarity+Aroma+Body+Oakiness, data=B11)
step(wine.null, scope=list(lower=wine.null, upper=wine.full), direction="both")
wine.null <- lm(Quality~1, data=B11)
wine.full <- lm(Quality~Flavor+Clarity+Aroma+Body+Oakiness, data=B11)
step(wine.null, scope=list(lower=wine.null, upper=wine.full), direction="both")
A <- lm(Quality~I(Region==1)+I(Region==2)+
Flavor+Oakiness, data=B11)
B <- lm(Quality ~ Flavor + Oakiness + Aroma, data = B11)
confint(A)
confint(B)
confint(predict(A,data=B11$.-Quality))
